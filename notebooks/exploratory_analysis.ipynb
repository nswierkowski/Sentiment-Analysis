{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza eksploracyjna\n",
    "\n",
    "Poniższy notebook postara się przeanalizować rozpatrywany zbiór danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/processed/reviews.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizowany zbiór posiada 46 kolumn, z czego duża część posiada puste wartości w zbiorze danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null = df.notnull().mean() * 100\n",
    "print(not_null[not_null < 100].sort_values(ascending=False))\n",
    "\n",
    "print(f'Columns not having empty values count: {not_null[not_null == 100].count()}')\n",
    "print(f'Columns having empty values count: {not_null[not_null < 100].count()}')\n",
    "print(f'Total columns count: {not_null.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blisko połowa kolumn posiada pewne puste wartości, ale większość z nich posiada 50% nie pustych wartości. Wyjątek stanowią helpfulness, child_max_price, child_min_price, value_price_usd, sale_price_usd i variation_desc. Szczególnie ostatnie 3 posiadają zdecydowaną większość rekordów pustych, więc ich użyteczność jest zdaje się znikoma. Stąd prawdopodobnie należy nie brać ich pod uwagę w trakcie budowy modelu.\n",
    "\n",
    "Dla kolumn, w których większość wartości jest niepustych, można zdecydować się na uzupełnienie ich medianą kolumny lub uzupełnić wartością innego najbardziej podobnego wiersza, który posiada dany atrybut nie pusty.\n",
    "\n",
    "Rozkład kolumny \"LABEL-rating\" prezentuje się następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['LABEL-rating'].value_counts().sort_index().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższy wykres pokazuje, że w zbiorze danych mamy do czynienia z niezrównoważoną klasą. Wartości 1 i 2 są znacznie mniej reprezentowane niż wartości 3, 4 i 5. Szczególnie klasa 5 jest reprezentowana przez większość rekordów. Może to sugerować, że korzystne będzie wykorzystanie modelu, który będzie odporny na nierówną dystrybucję zbioru wynikowego.\n",
    "\n",
    "Co więcej powyższy wykres prezentuje, że klasa wynikowa to wartość numeryczna. Spośród pozostałych kolumn liczba wartości numerycznych i kategorycznych prezentuje się następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(f'Numeric columns count: {len(numeric_columns)}')\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(f'Categorical columns count: {len(categorical_columns)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczba wartości numerycznych jest podobna do liczby wartości kategorycznych.\n",
    "\n",
    "Oceńmy jak dane numeryczne są powiązane ze sobą:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr = df.select_dtypes(include=['int64', 'float64']).corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Większość cech nie jest ze sobą skorelowane, choć występują wyjątki np. powiązanie między loves_count i rating, a także sales_price_usd oraz rating.\n",
    "Występuje wiele niepowiązanych atrybutów co może sugerować, że warto będzie zweryfikować użyteczność modelu Naive Bayess.\n",
    "\n",
    "Klasa docelowa koreluje z atrybutami 'rating' (średnią ocen danego produktu), sales_price_usd (choć tu należy mieć na uwadzę, małą liczbę rekordów), helpfulness, total_feedback_count, neg_total_feedback_count, pos_total_feedback_count a także contains_exclamation_point. Co można zobaczyć dokładniej poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.select_dtypes(include=['int64', 'float64']).corr()['LABEL-rating'].drop(labels='LABEL-rating').apply(abs).sort_values(ascending=False).plot(kind='bar')\n",
    "plt.title('Correlation with LABEL rating')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żadna cecha nie przewyższa wartości korelacji 0.25, ale jest kilka cech, które sugerują że możliwe będzie na ich podstawie wyznaczenie klasy LABEL-rating. Najmniej korelacji wykazują child_min_price oraz limited_edition.\n",
    "\n",
    "Przeanalizujmy dane tekstowe - zacznijmy od wykrycia najbardziej powtarzalnych słów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import heapq\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "download_dir = \"/app/data/nltk_data\"\n",
    "nltk.data.path.append(download_dir)\n",
    "nltk.download(info_or_id='stopwords', download_dir=download_dir)\n",
    "\n",
    "all_text = \" \".join(df[\"review_text\"].astype(str)).lower()\n",
    "all_text = re.sub(r'[\\n\\r\\t.,!?;:\"\\']', ' ', all_text)\n",
    "stopwords = set(stopwords.words('english'))\n",
    "all_text = \" \".join([word for word in all_text.split() if word not in stopwords])\n",
    "\n",
    "word_counter = {}\n",
    "for word in all_text.split():\n",
    "    word_counter[word] = word_counter.get(word, 0) + 1\n",
    "    \n",
    "print(f'Total words count: {len(word_counter)}')\n",
    "\n",
    "n = 100\n",
    "largest_n = heapq.nlargest(n, word_counter, key=word_counter.get)  \n",
    "largest_values = {key: word_counter[key] for key in largest_n}  \n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "word_counter = dict(sorted(largest_values.items(), key=lambda item: item[1], reverse=True))\n",
    "plt.bar(word_counter.keys(), word_counter.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Word frequency')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli zignorujemy tzw. stop words jak np. 'and', 'the' to otrzymamy że słowa 'skin', 'product', 'love' - o ile te dwa pierwsze słowa dotyczą bardziej opisy produktu to już występowanie 'love' czy 'great' sugeruje że raczej ocena jest pozytywna. Być może warto wyliczyć wszystkie takie słowa i umieścić, jako nową kolumne.\n",
    "\n",
    "Rozpatrzmy jak poszczególne słowa rozpatrują się w danej klasie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "rating_values = sorted(list(df['LABEL-rating'].value_counts().index))\n",
    "text_analysis = {\n",
    "    'LABEL-rating': rating_values,\n",
    "    'Word count': []\n",
    "}\n",
    "\n",
    "def get_n_common_words(n, rating):\n",
    "    all_text = \" \".join(df[df['LABEL-rating'] == rating][\"review_text\"].astype(str)).lower()\n",
    "    all_text = re.sub(r'[\\n\\r\\t.,!?;:\"\\']', ' ', all_text)\n",
    "    all_text = \" \".join([word for word in all_text.split() if word not in stopwords])\n",
    "\n",
    "    text_analysis['Word count'].append(len(all_text.split()))\n",
    "\n",
    "    word_counter_for_class = {}\n",
    "    for word in all_text.split():\n",
    "        word_counter_for_class[word] = word_counter_for_class.get(word, 0) + 1\n",
    "\n",
    "    largest_n = heapq.nlargest(n, word_counter_for_class, key=word_counter_for_class.get)\n",
    "    return {key: word_counter_for_class[key] for key in largest_n}\n",
    "\n",
    "num_ratings = len(rating_values)\n",
    "cols = 2  \n",
    "rows = (num_ratings // cols) + (num_ratings % cols > 0)  \n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "axes = axes.flatten() \n",
    "\n",
    "for i, value in enumerate(rating_values):\n",
    "    word_counter = get_n_common_words(50, value)\n",
    "    word_counter = dict(sorted(word_counter.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.bar(word_counter.keys(), word_counter.values())\n",
    "    ax.set_xticklabels(word_counter.keys(), rotation=90)\n",
    "    ax.set_title(f'Word frequency for rating {value}')\n",
    "    ax.set_xlabel('Words')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for rating, count in zip(text_analysis['LABEL-rating'], text_analysis['Word count']):\n",
    "    print(f'{rating}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższe wykresy prezentują że w przypadku klas 1, 2, i 3 nie występują m.in. słowa 'love', 'great'. W przypadku klasy 1 występują słowa takie, jak 'break', 'broke', sugerujące że produkt może być wadliwy.\n",
    "\n",
    "W przypadku liczności słów rozkłada się podobnie do liczby rekordów powiazaną z daną klasą. Rozpatrzmy to względem liczby rekordów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rating, count in zip(text_analysis['LABEL-rating'], text_analysis['Word count']):\n",
    "    records_of_rating = df[df['LABEL-rating'] == rating].shape[0]\n",
    "    print(f'Rating {rating}: {count//records_of_rating} words for record')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy że liczba słów na rekord jest bardzo podobna dla każdej klasy stąd nie można rozpatrywać długości jako atrybutu mogącego pomóc rozpoznać ocene.\n",
    "\n",
    "W przypadku pozostałych miar dotyczących tekstu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "text_analysis[\"exclamation_point_counter\"] = []\n",
    "for rating in text_analysis['LABEL-rating']:\n",
    "    text_analysis[\"exclamation_point_counter\"].append(df[df['LABEL-rating'] == rating]['contains_exclamation_point'].mean())\n",
    "    records_of_rating = df[df['LABEL-rating'] == rating].shape[0]\n",
    "    print(f'Rating {rating}: {text_analysis[\"exclamation_point_counter\"][-1]} exclamation_point mean')\n",
    "    \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(text_analysis['LABEL-rating'], text_analysis[\"exclamation_point_counter\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Exclamation point counter')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Mean exclamation point counter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Średnie występowanie wykrzyknika sugeruje że opinia jest skrajna - albo bardzo negatywna albo pozytywna\n",
    "\n",
    "Podobnie wygląda to w drugiej dodanej kolumnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analysis[\"contains_capslock\"] = []\n",
    "for rating in text_analysis['LABEL-rating']:\n",
    "    text_analysis[\"contains_capslock\"].append(df[df['LABEL-rating'] == rating]['contains_capslock'].mean())\n",
    "    records_of_rating = df[df['LABEL-rating'] == rating].shape[0]\n",
    "    print(f'Rating {rating}: {text_analysis[\"contains_capslock\"][-1]} contains_capslock mean')\n",
    "    \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(text_analysis['LABEL-rating'], text_analysis[\"contains_capslock\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Capslock count in each class')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Mean capslock counter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj różnice są mniej widoczne ale podobnie najczęściej pisanie słów dużymi literami występuje w skrajnych opiniach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
